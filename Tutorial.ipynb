{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will help you to understand all the APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from core.data_loader import DataLoader\n",
    "from core.resnet import *\n",
    "from utils.callbacks import callbacks\n",
    "from utils.misc_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]...  1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Limiting Tensorflow debugging message\n",
    "\n",
    "depth = 56 # No of layers to be used to build ResNet model\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "# TF GPU memory graph\n",
    "limit_gpu() # Useful for local system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data loader\n",
    "\n",
    "The DataLoader() support two data configration:\n",
    "1. Data is in seprate directory for training and validation data\n",
    "2. Data is in common directory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a data loader\n",
    "data_loader = DataLoader(validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is in seprate directory\n",
    "train_generator = data_loader.from_dir(directory='path/to/training_dataset')\n",
    "val_generator = data_loader.from_dir(directory='path/to/validation_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is in common directory\n",
    "\"\"\"\n",
    "DataLoader.from_common_dir() return a data generator & xtest, ytest used for validation data.\n",
    "DataLoader also store lots static values like num_classes, train_len(no of training data points),\n",
    "val_len(no of validation data points, etc which will be needed)\n",
    "\n",
    "\"\"\"\n",
    "data_generator,xtest, ytest = data_loader.from_common_dir(directory='path/to/dataset',\n",
    "                                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Building ResNetV2 model\n",
    "\n",
    "Four types of confrigation are supported:\n",
    "\n",
    "1. Build a complete ResNetV2 model with n no of residual layers with Fully connected layers included\n",
    "2. Add n no of ResNetV2 layers in your already created model\n",
    "2. Fine Tune ResNetV2 with fully connected layer included\n",
    "3. Fine Tune ResNetV2 with fully connected layer not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build a complete ResNetV2 model with n no of residual layers with Fully connected layers included\n",
    "model = build_resnet_model(\n",
    "    input_shape=(32, 32, 3),\n",
    "    depth=depth,\n",
    "    num_classes=data_loader.num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Add n no of ResNetV2 layers in your already created model\n",
    "\"\"\"\n",
    "Extra care have to taken in this method for matching the tensor shape of \n",
    "itermediate resent layer\n",
    "\"\"\"\n",
    "inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "X = tf.keras.layers.Conv2D(64,\n",
    "                        padding='same',\n",
    "                        kernel_regularizer=l2(1e-4))(inputs)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "res_layer = build_resnet_layer(inputs=X, num_filters_in=64, depth=5)\n",
    "\n",
    "y = Flatten()(res_layer)\n",
    "y = Dense(512, activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dropout(0.5)(y)\n",
    "\n",
    "outputs = Dense(num_classes,\n",
    "                    activation='softmax')(y)\n",
    "\n",
    "# Instantiate model.\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fine Tune ResNetV2 with fully connected layer included\n",
    "\"\"\"\n",
    "Use this if you wish to fine tune on pretrained imagenet weights.\n",
    "A FC layer have already appened here. if you wish to used your desired \n",
    "FC layer then used core.resnet.build_resnet_pretrained_customized()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = build_resnet_pretrained(input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fine Tune ResNetV2 with fully connected layer not included\n",
    "X = build_resnet_pretrained_customized(input_shape = (224,224,3)\n",
    "                                       \n",
    "# Append FC layer\n",
    "y = X.output\n",
    "y = Flatten()(y)\n",
    "y = Dense(10, activation='softmax')(y)\n",
    "\n",
    "# Combining base model FC head model\n",
    "model = Model(inputs=x.input, outputs=y)\n",
    "\n",
    "# Freezing weights\n",
    "\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 (Optional): Use callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It is optional though advisable to use them\n",
    "\"\"\"\n",
    "callbacks = callbacks(\n",
    "    save_path='./assets/weights/exp2',\n",
    "    depth=depth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(amsgrad=True, decay=0.001/epochs),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Starting Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=data_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=int(data_loader.train_len/batch_size),\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(xtest, ytest),\n",
    "    validation_steps=int(data_loader.val_len/batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training\n",
    "visualize(\n",
    "    history=history.history,\n",
    "    save_dir='./assets/logs'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
